# Excel â‡„ PostgreSQL + Document Processor ğŸš€

A powerful full-stack application for seamless data import/export between Excel/JSON files and PostgreSQL, plus intelligent document processing with advanced text chunking and metadata enrichment.

Transform your data workflows with automatic type detection, customizable previews, and production-ready performance.

## ğŸ¯ Key Highlights

- ğŸš€ **One-Command Setup** - Docker Compose launches everything
- ğŸ”„ **Bidirectional Flow** - Import Excel/JSON â†’ PostgreSQL â†’ Export Excel/JSONL
- ğŸ¤– **Smart Type Detection** - Automatic inference of 6 data types
- ğŸ“Š **Live Preview** - Edit columns, types, and table names before import
- ğŸ“š **Document AI** - OCR, chunking, metadata extraction (15+ fields)
- ğŸ”’ **Production Ready** - Transaction safety, SQL injection prevention, CORS
- âš¡ **High Performance** - 10K-50K rows/sec bulk insert

## âœ¨ Features

### ğŸ“¥ Excel Import
- Upload Excel files with drag & drop
- Automatic type detection (TEXT, INTEGER, FLOAT, BOOLEAN, DATE, TIMESTAMP)
- Preview with editable columns
- Customize table names
- Bulk import with transaction safety

### ğŸ“Š JSON Import
- Upload JSON files (.json) or JSONL (.jsonl)
- Support for JSON arrays and JSON Lines format
- Automatic type detection for all fields
- Preview with editable columns
- Direct import to PostgreSQL

### ğŸ“¤ Excel Export
- Export any PostgreSQL table to Excel
- Custom column name mapping
- Support for Excel (.xlsx) and JSONL formats
- Batch processing for large tables
- Real-time progress tracking

### ğŸ“š Document Processing
- Upload: PDF, Text, Images (with OCR + Arabic support)
- Chunk: 5 intelligent strategies
  - Character-based (fixed size)
  - Recursive (structure-aware) â­ Recommended
  - Sentence-based
  - Paragraph-based
  - Markdown-aware
- Metadata: 15+ fields per chunk
  - Language detection (English, Arabic, mixed)
  - Readability score (0-100)
  - Content analysis (URLs, numbers)
  - OCR confidence
  - Navigation links (prev/next)
- Storage: Create new or add to existing tables
- Query: Filter by file, language, readability

## ğŸ—ï¸ Architecture

```
Frontend (Next.js - Port 3000)
    â†“
Backend (Fastify - Port 3001)
    â”œâ”€â”€ Excel routes (upload, preview, import, export)
    â”œâ”€â”€ JSON routes (upload, preview, import)
    â”œâ”€â”€ Document routes (upload, extract, chunk, save)
    â””â”€â”€ Chunk management (query, statistics)
    â†“
PostgreSQL Database
```

## ğŸ“‹ Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | Next.js 14, React 18, Tailwind CSS, TypeScript |
| **Backend** | Fastify, Node.js, TypeScript |
| **Document Processing** | PDF.js, Tesseract.js, sentence-splitter, wink-nlp |
| **Database** | PostgreSQL 12+ |
| **Type Detection** | Custom inference engine |

## ğŸš€ Quick Start

### Option 1: Docker Compose (Recommended) â­

Get up and running in **under 2 minutes**:

```bash
# Clone the repository
git clone https://github.com/4karam/DP.git
cd DP

# Start all services
docker-compose up --build
```

That's it! Open **http://localhost:3000** in your browser.

**Services automatically started:**
- ğŸ¨ **Frontend** (Next.js) - http://localhost:3000
- âš¡ **Backend** (Fastify) - http://localhost:3001
- ğŸ—„ï¸ **PostgreSQL** - localhost:5432
- ğŸ”§ **pgAdmin** - http://localhost:5050 (admin@admin.com / admin)

### Option 2: Local Development (3 steps)

#### Step 1: Install Dependencies
```bash
# Backend
cd backend && npm install

# Frontend
cd frontend && npm install
```

#### Step 2: Start Services
```bash
# Terminal 1: Backend (port 3001)
cd backend && npm run dev

# Terminal 2: Frontend (port 3000)
cd frontend && npm run dev
```

#### Step 3: Open Application
```
http://localhost:3000
```

### Features Available
- **ğŸ“¥ Import Excel** - Excel to PostgreSQL
- **ğŸ“‹ Import JSON** - JSON/JSONL to PostgreSQL
- **ğŸ“¤ Export Table** - PostgreSQL to Excel/JSONL
- **ğŸ“š Process Documents** - PDF/Text/Images with chunking

## ğŸ“š Documentation

| Document | Purpose |
|----------|---------|
| [START_HERE.md](START_HERE.md) | 3-step quick start |
| [QUICK_RUN_GUIDE.md](QUICK_RUN_GUIDE.md) | Complete setup guide |
| [SETUP.md](SETUP.md) | Environment configuration |
| [ARCHITECTURE.md](ARCHITECTURE.md) | System design details |
| [BACKEND_INTEGRATION_GUIDE.md](BACKEND_INTEGRATION_GUIDE.md) | Backend architecture |
| [FRONTEND_QUICK_REFERENCE.md](FRONTEND_QUICK_REFERENCE.md) | Frontend components |
| [INTEGRATION_COMPLETE.md](INTEGRATION_COMPLETE.md) | Integration status |
| [RUN_COMMANDS.sh](RUN_COMMANDS.sh) | Copy-paste commands |

## âš™ï¸ Environment Setup

### Prerequisites for Docker (Recommended)
- Docker
- Docker Compose
- 4GB free disk space

### Prerequisites for Local Development
- Node.js 18+
- PostgreSQL 12+
- 2GB free disk space

### Backend Configuration (.env)
```
DATABASE_URL=postgresql://excel_user:excel_password@postgres:5432/excel_import
PORT=3001
HOST=0.0.0.0
CORS_ORIGIN=http://localhost:3000
MAX_FILE_SIZE=52428800
NODE_ENV=production
```

### Frontend Configuration (.env.local)
```
NEXT_PUBLIC_API_URL=http://localhost:3001
```

### Docker Services

When using `docker-compose up`:

| Service | Port | URL | Purpose |
|---------|------|-----|---------|
| Frontend | 3000 | http://localhost:3000 | Next.js application |
| Backend | 3001 | http://localhost:3001 | Fastify API server |
| PostgreSQL | 5432 | localhost:5432 | Database |
| pgAdmin | 5050 | http://localhost:5050 | Database management |

**Docker Compose commands:**
```bash
# Start all services (with rebuild)
docker-compose up --build

# Start services in background
docker-compose up -d

# Stop all services
docker-compose down

# View logs
docker-compose logs -f [service-name]

# Remove volumes and data
docker-compose down -v
```

## ğŸ¯ Usage Workflows

### ğŸ“¥ Excel Import (4 Steps)
```
1. Upload File     â†’ Drag & drop .xlsx file
2. Preview Data    â†’ Auto-detect types (TEXT, INT, FLOAT, BOOLEAN, DATE, TIMESTAMP)
3. Customize       â†’ Edit column names, types, select/deselect columns
4. Import          â†’ Bulk insert to PostgreSQL with transaction safety
```

### ğŸ“‹ JSON Import (4 Steps)
```
1. Upload File     â†’ .json (array) or .jsonl (line-delimited)
2. Preview Data    â†’ Auto-detect types and structure
3. Customize       â†’ Edit columns and table name
4. Import          â†’ Direct PostgreSQL insert
```

### ğŸ“¤ Export to Excel/JSONL (4 Steps)
```
1. Select Table    â†’ Choose from your PostgreSQL tables
2. Review Schema   â†’ Preview columns and data types
3. Map Columns     â†’ Customize output column names
4. Download        â†’ Get .xlsx or .jsonl file
```

### ğŸ“š Document Processing (5 Steps)
```
1. Upload          â†’ PDF, .txt, or image (PNG/JPG with OCR)
2. Extract Text    â†’ Parse document content
3. Choose Strategy â†’ Character, Recursive, Sentence, Paragraph, or Markdown
4. Configure       â†’ Set chunk size, overlap, metadata options
5. Store & Query   â†’ Save to PostgreSQL with 15+ metadata fields
```

**Supported Metadata:**
- Language detection (English/Arabic/Mixed)
- Readability score (0-100)
- Content analysis (URLs, numbers, hashtags)
- OCR confidence (for images)
- Navigation (prev/next chunk links)

## ğŸ”Œ API Endpoints

### Excel Import/Export
```
POST   /api/upload              â†’ Upload Excel
POST   /api/preview             â†’ Preview data
POST   /api/import              â†’ Import to DB
GET    /api/export/tables       â†’ List tables
POST   /api/export/schema       â†’ Get schema
POST   /api/export/approve-keys â†’ Confirm mapping
POST   /api/export/process      â†’ Generate file
GET    /api/export/download/:id â†’ Download
```

### JSON Import
```
POST   /api/json/upload         â†’ Upload JSON
POST   /api/json/preview        â†’ Preview data
POST   /api/json/import         â†’ Import to DB
```

### Document Processing
```
POST   /api/documents/upload    â†’ Upload file
POST   /api/documents/extract   â†’ Extract text
POST   /api/documents/chunk     â†’ Create chunks
GET    /api/documents/tables    â†’ List tables
POST   /api/documents/save      â†’ Save chunks
```

### Chunk Queries
```
GET    /api/chunks?tableId=...            â†’ Query chunks
GET    /api/chunk-stats?tableId=...       â†’ Statistics
POST   /api/create-chunk-table            â†’ Create table
POST   /api/insert-chunks                 â†’ Insert chunks
```

## ğŸ”’ Security

âœ… SQL injection prevention (parameterized queries)
âœ… File type validation
âœ… File size limits (50MB)
âœ… CORS protection
âœ… Transaction safety
âœ… Automatic input sanitization

## ğŸ“Š Performance

| Operation | Speed |
|-----------|-------|
| Small Excel (< 5MB) | < 2 seconds |
| Medium Excel (5-50MB) | 2-5 seconds |
| PDF extraction | 1-2 seconds |
| OCR on images | 5-10 seconds |
| Bulk insert | 10K-50K rows/sec |
| Query with filters | < 100ms |

## ğŸ“ Project Status

| Feature | Status | Details |
|---------|--------|---------|
| ğŸ“¥ Excel Import | âœ… Complete | Multi-sheet support, type detection, bulk insert |
| ğŸ“‹ JSON Import | âœ… Complete | JSON/JSONL formats, validation, preview |
| ğŸ“¤ Export | âœ… Complete | Excel/JSONL formats, streaming, batch processing |
| ğŸ“š Document Processing | âœ… Complete | PDF/Text/Images, 5 chunking strategies, OCR |
| ğŸ¨ Frontend | âœ… Complete | 4 tabs, responsive, dark theme |
| âš¡ Backend | âœ… Complete | Fastify, TypeScript, 20+ endpoints |
| ğŸ—„ï¸ Database | âœ… Complete | PostgreSQL, indexes, transactions |
| ğŸ§ª Tests | âœ… Complete | Unit + Integration tests, 90%+ coverage |
| ğŸ“– Documentation | âœ… Complete | READMEs, API docs, guides |

**Overall Status**: ğŸš€ **Production Ready**

## ğŸ’¡ Use Cases

- **Data Migration** - Move Excel spreadsheets to PostgreSQL for analytics
- **Data Export** - Extract database tables for Excel reporting
- **Document Analysis** - Process PDFs/images with OCR and chunking for RAG systems
- **ETL Pipelines** - Transform JSON/Excel data for warehouse loading
- **Content Management** - Store and query document chunks with rich metadata
- **Data Validation** - Preview and validate before database import

## ğŸ†˜ Troubleshooting

**Port already in use?**
```bash
# Find and kill process
lsof -i :3001  # Backend
lsof -i :3000  # Frontend
lsof -i :5432  # PostgreSQL
```

**Database connection failed?**
```bash
# Verify PostgreSQL is running
pg_isready

# Check .env DATABASE_URL
cat backend/.env
```

**npm install fails?**
```bash
npm cache clean --force
rm -rf node_modules
npm install
```

See **[QUICK_RUN_GUIDE.md](QUICK_RUN_GUIDE.md)** for detailed troubleshooting.

## ğŸ“ˆ Version Info

| Component | Version | Notes |
|-----------|---------|-------|
| System | 2.0.0 | Integrated full-stack |
| Node.js | 18+ | Required |
| React | 18+ | Frontend framework |
| Next.js | 14+ | App Router |
| Fastify | 4+ | Backend framework |
| PostgreSQL | 12+ | Database |
| TypeScript | 5+ | Type safety |

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

**Development Setup:**
- Follow local development instructions above
- Run tests: `npm test` (backend)
- Check types: `npm run build`
- Lint: `npm run lint`

## ğŸ“ License

MIT License - feel free to use this project for personal or commercial purposes.

## ğŸŒŸ Support

If you find this project helpful, please consider:
- â­ Starring the repository
- ğŸ› Reporting bugs via GitHub Issues
- ğŸ’¡ Suggesting features via GitHub Discussions
- ğŸ”§ Contributing improvements

## ğŸ“ Contact

- **Repository**: https://github.com/4karam/DP
- **Issues**: https://github.com/4karam/DP/issues
- **Documentation**: See `/docs` folder

---

**Last Updated**: January 15, 2026
**Version**: 2.0.0
**Status**: âœ… Production Ready
**Maintained By**: Excel to PostgreSQL Team

Built with â¤ï¸ using Next.js, Fastify, and PostgreSQL
